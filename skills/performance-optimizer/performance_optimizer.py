#!/usr/bin/env python3
"""
Performance Optimizer - æ€§èƒ½ä¼˜åŒ–å·¥å…·
ä»£ç å¤æ‚åº¦åˆ†æã€æ€§èƒ½ç“¶é¢ˆå®šä½ã€èµ„æºä½¿ç”¨åˆ†æã€ä¼˜åŒ–å»ºè®®
"""

import os
import sys
import ast
import time
import cProfile
import pstats
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from collections import defaultdict


class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æå™¨"""

    def __init__(self, target_path: str = None):
        self.target_path = Path(target_path) if target_path else Path.cwd()
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "target": str(self.target_path),
            "analysis": {
                "complexity": {},
                "bottlenecks": [],
                "resources": {},
                "recommendations": []
            }
        }

    def analyze_complexity(self) -> Dict[str, Any]:
        """åˆ†æä»£ç å¤æ‚åº¦"""
        complexity_data = {}

        # éå†Pythonæ–‡ä»¶
        py_files = list(self.target_path.rglob("*.py"))

        for py_file in py_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    source = f.read()

                tree = ast.parse(source)
                visitor = ComplexityVisitor()
                visitor.visit(tree)

                complexity_data[str(py_file)] = {
                    "cyclomatic": visitor.max_complexity,
                    "functions": visitor.function_complexity,
                    "classes": visitor.class_count,
                    "lines": source.count('\n') + 1
                }

            except Exception as e:
                complexity_data[str(py_file)] = {"error": str(e)}

        self.results["analysis"]["complexity"] = complexity_data
        return complexity_data

    def profile_code(self, file_path: str = None) -> List[Dict[str, Any]]:
        """åˆ†æä»£ç æ€§èƒ½ï¼ˆä½¿ç”¨cProfileï¼‰"""
        if not file_path:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶ï¼Œåˆ†ææ•´ä¸ªç›®å½•
            return []

        profiler = cProfile.Profile()

        try:
            # å¯¼å…¥å¹¶æ‰§è¡Œæ¨¡å—
            import importlib.util
            spec = importlib.util.spec_from_file_location("test_module", file_path)
            module = importlib.util.module_from_spec(spec)

            # æ‰§è¡Œå¹¶åˆ†æ
            profiler.enable()
            spec.loader.exec_module(module)
            profiler.disable()

            # è·å–ç»Ÿè®¡ç»“æœ
            stats = pstats.Stats(profiler)

            # æå–ç“¶é¢ˆå‡½æ•°
            bottlenecks = []
            stats.strip_dirs()
            stats.sort_stats('cumulative')

            stats_stream = pstats.Stats(profiler, stream=None)
            stats_stream.strip_dirs()
            stats_stream.sort_stats('cumulative')

            # è·å–å‰20ä¸ªç“¶é¢ˆ
            stats_stream.stream = None
            stats_data = []
            for func, (cc, nc, tt, ct, callers) in stats_stream.get_stats_profile().func_profiles.items():
                stats_data.append({
                    "function": f"{func[0]}:{func[1]}({func[2]})",
                    "calls": cc,
                    "total_time": tt,
                    "cumulative_time": ct
                })

            # æ’åºå¹¶å–å‰20
            stats_data.sort(key=lambda x: x['cumulative_time'], reverse=True)
            bottlenecks = stats_data[:20]

            self.results["analysis"]["bottlenecks"] = bottlenecks
            return bottlenecks

        except Exception as e:
            print(f"âš ï¸  æ€§èƒ½åˆ†æå¤±è´¥: {e}")
            return []

    def analyze_resources(self) -> Dict[str, Any]:
        """åˆ†æèµ„æºä½¿ç”¨æƒ…å†µ"""
        # åˆ†ææ–‡ä»¶å¤§å°
        file_sizes = []
        total_size = 0

        for file_path in self.target_path.rglob("*"):
            if file_path.is_file():
                size = file_path.stat().st_size
                file_sizes.append({
                    "file": str(file_path.relative_to(self.target_path)),
                    "size": size
                })
                total_size += size

        # æ‰¾å‡ºæœ€å¤§çš„æ–‡ä»¶
        file_sizes.sort(key=lambda x: x['size'], reverse=True)
        top_files = file_sizes[:10]

        self.results["analysis"]["resources"] = {
            "total_size": total_size,
            "file_count": len(file_sizes),
            "largest_files": top_files
        }

        return self.results["analysis"]["resources"]

    def generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # åŸºäºå¤æ‚åº¦çš„å»ºè®®
        complexity = self.results["analysis"].get("complexity", {})
        for file, data in complexity.items():
            if isinstance(data, dict) and "cyclomatic" in data:
                if data["cyclomatic"] > 10:
                    recommendations.append(
                        f"âš ï¸  {file}: å¤æ‚åº¦è¿‡é«˜({data['cyclomatic']})ï¼Œå»ºè®®æ‹†åˆ†å‡½æ•°"
                    )

        # åŸºäºç“¶é¢ˆçš„å»ºè®®
        bottlenecks = self.results["analysis"].get("bottlenecks", [])
        if bottlenecks:
            top_bottleneck = bottlenecks[0]
            if top_bottleneck['cumulative_time'] > 1.0:
                recommendations.append(
                    f"ğŸ”¥ æ€§èƒ½ç“¶é¢ˆ: {top_bottleneck['function']}"
                    f" è€—æ—¶{top_bottleneck['cumulative_time']:.2f}ç§’ï¼Œå»ºè®®ä¼˜åŒ–"
                )

        # åŸºäºèµ„æºçš„å»ºè®®
        resources = self.results["analysis"].get("resources", {})
        if resources.get("total_size", 0) > 100 * 1024 * 1024:  # >100MB
            recommendations.append(
                f"ğŸ’¾ æ€»å¤§å°è¶…è¿‡100MBï¼Œå»ºè®®æ¸…ç†ä¸å¿…è¦æ–‡ä»¶æˆ–ä½¿ç”¨å‹ç¼©"
            )

        # é€šç”¨å»ºè®®
        if not recommendations:
            recommendations.append("âœ… ä»£ç è´¨é‡è‰¯å¥½ï¼Œæš‚æ— æ˜æ˜¾æ€§èƒ½é—®é¢˜")

        self.results["analysis"]["recommendations"] = recommendations
        return recommendations

    def analyze(self, profile_file: str = None) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´åˆ†æ"""
        print(f"ğŸ” åˆ†æç›®æ ‡: {self.target_path}")

        # 1. åˆ†æå¤æ‚åº¦
        print("  ğŸ“Š åˆ†æä»£ç å¤æ‚åº¦...")
        self.analyze_complexity()

        # 2. æ€§èƒ½åˆ†æï¼ˆå¦‚æœæŒ‡å®šäº†æ–‡ä»¶ï¼‰
        if profile_file and os.path.exists(profile_file):
            print(f"  â±ï¸  åˆ†ææ€§èƒ½: {profile_file}")
            self.profile_code(profile_file)

        # 3. åˆ†æèµ„æº
        print("  ğŸ’¾ åˆ†æèµ„æºä½¿ç”¨...")
        self.analyze_resources()

        # 4. ç”Ÿæˆå»ºè®®
        print("  ğŸ’¡ ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
        self.generate_recommendations()

        return self.results

    def print_report(self):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("æ€§èƒ½ä¼˜åŒ–æŠ¥å‘Š")
        print("=" * 60)

        # å¤æ‚åº¦åˆ†æ
        print("\nğŸ“Š ä»£ç å¤æ‚åº¦åˆ†æ")
        print("-" * 60)
        complexity = self.results["analysis"]["complexity"]
        for file, data in complexity.items():
            if isinstance(data, dict) and "cyclomatic" in data:
                print(f"{file}:")
                print(f"  å¤æ‚åº¦: {data['cyclomatic']}")
                print(f"  å‡½æ•°æ•°: {len(data.get('functions', {}))}")
                print(f"  è¡Œæ•°: {data.get('lines', 0)}")

        # æ€§èƒ½ç“¶é¢ˆ
        bottlenecks = self.results["analysis"].get("bottlenecks", [])
        if bottlenecks:
            print("\nâ±ï¸  æ€§èƒ½ç“¶é¢ˆï¼ˆTop 10ï¼‰")
            print("-" * 60)
            for i, b in enumerate(bottlenecks[:10], 1):
                print(f"{i}. {b['function']}")
                print(f"   è°ƒç”¨: {b['calls']}, è€—æ—¶: {b['cumulative_time']:.4f}s")

        # ä¼˜åŒ–å»ºè®®
        print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®")
        print("-" * 60)
        recommendations = self.results["analysis"]["recommendations"]
        for rec in recommendations:
            print(rec)

        print("\n" + "=" * 60)

    def save_results(self, output_file: str = None):
        """ä¿å­˜åˆ†æç»“æœ"""
        if not output_file:
            output_file = self.target_path / "performance_report.json"

        output_file = Path(output_file)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        print(f"\næŠ¥å‘Šå·²ä¿å­˜: {output_file}")


class ComplexityVisitor(ast.NodeVisitor):
    """ASTè®¿é—®å™¨ï¼Œç”¨äºè®¡ç®—å¤æ‚åº¦"""

    def __init__(self):
        self.max_complexity = 1
        self.current_complexity = 1
        self.function_complexity = {}
        self.class_count = 0
        self.current_function = None

    def visit_FunctionDef(self, node):
        self.current_function = node.name
        self.current_complexity = 1
        self.generic_visit(node)
        self.function_complexity[node.name] = self.current_complexity
        self.max_complexity = max(self.max_complexity, self.current_complexity)
        self.current_function = None

    def visit_AsyncFunctionDef(self, node):
        self.visit_FunctionDef(node)

    def visit_ClassDef(self, node):
        self.class_count += 1
        self.generic_visit(node)

    def visit_If(self, node):
        self.current_complexity += 1
        self.generic_visit(node)

    def visit_While(self, node):
        self.current_complexity += 1
        self.generic_visit(node)

    def visit_For(self, node):
        self.current_complexity += 1
        self.generic_visit(node)

    def visit_With(self, node):
        self.current_complexity += 1
        self.generic_visit(node)

    def visit_Try(self, node):
        self.current_complexity += 1
        self.generic_visit(node)

    def visit_ExceptHandler(self, node):
        self.current_complexity += 1
        self.generic_visit(node)


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æ€§èƒ½ä¼˜åŒ–å·¥å…·")
    parser.add_argument("--analyze", metavar="PATH", help="åˆ†æä»£ç æ€§èƒ½")
    parser.add_argument("--profile", metavar="FILE", help="æ€§èƒ½åˆ†ææŒ‡å®šæ–‡ä»¶")
    parser.add_argument("--report", metavar="FILE", help="ç”ŸæˆæŠ¥å‘Š")
    parser.add_argument("--output", metavar="FILE", help="è¾“å‡ºæ–‡ä»¶")

    args = parser.parse_args()

    analyzer = PerformanceAnalyzer(args.analyze)

    if args.analyze:
        analyzer.analyze(args.profile)
        analyzer.print_report()
        analyzer.save_results(args.output)

    elif args.report:
        with open(args.report, 'r') as f:
            data = json.load(f)
        print(json.dumps(data, indent=2, ensure_ascii=False))

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
